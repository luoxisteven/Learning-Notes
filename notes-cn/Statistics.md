# 统计学 Statistics 

## 目录 Table of Contents
- [两类错误](#两类错误)
- [显著性水平、统计功效和 P 值](#显著性水平统计功效和-p-值)
- [置信区间](#置信区间)
- [方差分析 ANOVA](#方差分析-anova)
- [单边检验和双边检验](#单边检验和双边检验)
- [辛普森悖论](#辛普森悖论)
- [假设检验](#假设检验)
- [参数估计](#参数估计)
- [常见的统计检验](#常见的统计检验)
- [大数定理与中心极限定理](#大数定理与中心极限定理)
- [统计量和抽样分布](#统计量和抽样分布)
   - [卡方分布](#卡方分布)
   - [T分布](#t分布)
   - [F分布](#f分布)
- [A/B 测试](#ab-test)


## 两类错误

- **一类错误（假阳性）**：错误地拒绝了正确的原假设。  
  **举例**：假设一名无辜的人被控犯罪，这里零假设是“这个人是无辜的”，如果法庭错误地判定这个无辜的人有罪，那么就犯了一类错误。

- **二类错误（假阴性）**：未能拒绝错误的原假设。  
  **举例**：如果被告实际上是有罪的，但法庭判定他无罪，那么就犯了二类错误。

----
#### 一类错误和二类错误哪个更严重？

一般来说，一类错误（假阳性）通常被认为更严重。因为在统计中，原假设是我们想要去拒绝的，所以我们会把显著性水平 α 设置得较小，以减少犯一类错误的可能性。常见的 α 值为 0.05，表示我们愿意接受 5% 的概率去犯一类错误。

但在某些场景下，比如癌症筛查，`二类错误（假阴性）` 可能更严重。如果测试未能识别出实际存在的癌症（假阴性），患者可能错过最佳治疗时机。因此，需要根据具体应用场景来权衡。


## 显著性水平、统计功效和 P 值

- **显著性水平（α）**：研究者愿意接受的第一类错误（假阳性）的概率阈值。常见的 α 值为 0.05，意味着我们愿意接受 5% 的概率错误地拒绝零假设。
  
- **统计功效（1-β）**：正确拒绝零假设（检测到实际效应）的概率，表示避免犯二类错误（假阴性）的能力。统计功效越高，越有可能检测到实际存在的效应。

- **P 值**：在零假设为真的情况下，观察到当前数据结果的概率。P 值越小，表示在原假设为真的前提下，观测到这种结果的可能性越低，因此我们越倾向于拒绝零假设。

## 置信区间

- **置信区间**：用于估计总体参数的区间范围。在做区间估计时，置信区间表示根据样本数据推断的总体参数的可能范围。通常使用 95% 的置信区间，意味着我们有 95% 的信心总体参数落在此区间内。

## 不同类型的检验方法

- **t 检验**：用于比较两个样本均值是否存在显著差异，适用于总体方差未知或样本量较小的情况。

- **z 检验**：也用于比较两个样本均值，但适用于样本量较大或已知总体方差的情况。

- **卡方检验**：用于分类数据的独立性检验或拟合优度检验。独立性检验用于检查两个变量是否独立，拟合优度检验用于判断观察到的分类变量分布是否符合预期。

- **F 检验**：主要用于检验两个或多个组的方差是否显著不同，常见于方差分析（ANOVA），用于分析多个样本的均值是否存在显著差异。

## 方差分析 (ANOVA)

**ANOVA (方差分析)** 用于分析多个样本均值之间是否存在显著差异。通过比较组间变异和组内变异，来确定不同组的均值是否显著不同。ANOVA 计算的统计量 F 值的公式为：

$$
F = \frac{MSB}{MSE}
$$

其中，MSB 表示组间方差，MSE 表示组内方差。

## 单边检验和双边检验

- **单边检验**：用于假设中具有方向性预测时，测试效应是否显著。例如，研究者想验证新方案是否优于旧方案，会使用单边检验。

- **双边检验**：用于验证两个变量之间是否存在差异，而不考虑方向性。当研究者仅关心是否存在差异时，会使用双边检验。

- **单边检验**：用于检测效应是否朝着假设的单一方向发展。  
- **双边检验**：用于检测两个变量是否存在差异，不考虑方向性。


## 辛普森悖论

**辛普森悖论**指的是在某个条件下，当分别分析两组数据时，它们可能都会满足某种性质，但当数据合并分析时，却可能导致相反的结论。  
这意味着分开讨论和合并讨论会得出相反的结论。

### 举例

假设某医院的两位医生，医生A和医生B，分别治疗了两组病人。分别计算每位医生在两组病人中的治疗成功率时，可能会得出医生A的成功率更高。然而，当合并所有病人后，结果却可能显示医生B的成功率更高。这就是辛普森悖论的体现。

### 如何避免辛普森悖论？

1. **层次化分析**：
   - 对数据进行分层，按性别、年龄段或其他重要变量进行分组分析，而不是简单地合并所有数据。分层能更清晰地揭示变量之间的关系，避免合并导致的误导性结果。

2. **细分切割**：
   - 根据数据的背景和实际情况，将数据进行细分分析。对每个子集单独处理和分析，以确保不会因合并数据而失去重要信息。

3. **样本量和样本质量**：
   - 保证每个分组中的样本量足够大，且样本质量高。样本量不足可能导致统计上的不准确性，样本的选择偏差可能导致分析结果误导。



## 假设检验
- [假设检验(知乎)](https://zhuanlan.zhihu.com/p/86178674?utm_psn=1743869140127977472)
- 标准正态分布，也称为z分布


**假设检验**是对总体参数提出一个假设值，通过样本信息判断该假设是否成立的过程。  
- **原假设（Null Hypothesis）**：通常是我们希望去拒绝的假设，例如两组均值相等。  
- **备择假设（Alternative Hypothesis）**：与原假设互补，假设两组均值不相等。

### 假设检验中的两类错误：
- **一类错误（Type I Error）**：原假设实际为真，但被错误地拒绝，即假阳性。
- **二类错误（Type II Error）**：原假设实际为假，但未能拒绝，即假阴性。

### 显著性水平和 P 值
- **显著性水平（α）**：我们愿意接受的第一类错误的概率阈值。常见的 α 值为 0.05。
- **P 值**：在原假设为真的情况下，观察到当前结果的概率。P 值越小，越倾向于拒绝原假设。

## 参数估计

**参数估计**用于通过样本来推断总体参数，分为两种方法：
1. **点估计**：使用样本统计量（如均值）直接估计总体参数。  
2. **区间估计**：在给定的置信水平下，构建一个区间来估计总体参数。例如 95% 置信区间表示 95% 的可能性下总体参数落在该区间内。

 | 参数 | 抽样分布 | 置信区间 |
|------|----------|----------|
| $\mu$，$\sigma^2$ 已知 | $\dfrac{\bar{X} - \mu}{\sigma / \sqrt{n}} \sim N(0,1)$ | $\left[\bar{X} - \dfrac{\sigma}{\sqrt{n}} z_{\alpha/2},\ \bar{X} + \dfrac{\sigma}{\sqrt{n}} z_{\alpha/2} \right]$ |
| $\mu$，$\sigma^2$ 未知 | $\dfrac{\bar{X} - \mu}{S / \sqrt{n}} \sim t(n-1)$ | $\left[\bar{X} - \dfrac{S}{\sqrt{n}} t_{\alpha/2}(n-1),\ \bar{X} + \dfrac{S}{\sqrt{n}} t_{\alpha/2}(n-1) \right]$ |
| $\sigma^2$ | $\dfrac{(n - 1) S^2}{\sigma^2} \sim \chi^2(n - 1)$ | $\left[\dfrac{(n - 1) S^2}{\chi^2_{1 - \alpha/2}},\ \dfrac{(n - 1) S^2}{\chi^2_{\alpha/2}} \right]$ |
| $\mu_1 - \mu_2$ <br> ($\sigma_1^2,\ \sigma_2^2$ 已知) | $\dfrac{(\bar{X} - \bar{Y}) - (\mu_1 - \mu_2)}{\sqrt{\dfrac{\sigma_1^2}{n} + \dfrac{\sigma_2^2}{m}}} \sim N(0,1)$ | $\left[(\bar{X} - \bar{Y}) \pm z_{\alpha/2} \sqrt{\dfrac{\sigma_1^2}{n} + \dfrac{\sigma_2^2}{m}} \right]$ |
| $\mu_1 - \mu_2$ <br> ($\sigma_1^2 = \sigma_2^2 = \sigma^2$ 未知) | $\dfrac{(\bar{X} - \bar{Y}) - (\mu_1 - \mu_2)}{S_w \sqrt{1/n + 1/m}} \sim t(n + m - 2)$ | $\left[(\bar{X} - \bar{Y}) \pm t_{\alpha/2}(n + m - 2) S_w \sqrt{\dfrac{1}{n} + \dfrac{1}{m}} \right]$ |
| $\dfrac{\sigma_1^2}{\sigma_2^2}$ | $\dfrac{S_1^2 / \sigma_1^2}{S_2^2 / \sigma_2^2} \sim F(n - 1,\ m - 1)$ | $\left[\dfrac{S_1^2}{S_2^2 F_{1 - \alpha/2}(n - 1,\ m - 1)},\ \dfrac{S_1^2}{S_2^2 F_{\alpha/2}(n - 1,\ m - 1)} \right]$ |

 - 注意: 在未知方差时，如果大样本也可以用正态分布。$$z=（x-μ）/σ$$

### 置信区间
- [置信区间 CSDN](https://blog.csdn.net/Anne033/article/details/109739681?ops_request_misc=&request_id=&biz_id=102&utm_term=%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-109739681.142^v99^pc_search_result_base2&spm=1018.2226.3001.4187)


- **置信区间**是用样本数据估计总体参数的区间范围。  
- **置信水平**是置信区间包含总体参数的概率。常见的置信水平为 95%。
```
置信区间就是我去抽不同的样本去构建区间，有多少置信度（置信水平）的区间，能够包含真正的参数（比方说总体均值）。
置信度（置信水平）就是这些区间包含总体均值的概率。比方说，95%的置信水平表示：抽取的100个样本，有100个置信区间，其中有95个置信区间可能包含总体的真实平均值。

相当有信心落在这个置信区间内。
```

## 大数定理与中心极限定理

### 大数定理
- **弱大数定理**：随着样本量增加，样本均值以概率收敛于总体均值。  
- **强大数定理**：随着样本量的增加，样本均值几乎必然收敛于总体均值。

### 中心极限定理
- [中心极限定理 知乎](https://zhuanlan.zhihu.com/p/259280292)
- 当`样本独立同分布 Independent and Identically Distributed`，不管是从什么分布进行抽取，`在n足够大时（样本量足够大）`，“样本的均值”趋近于总体均值，样本方差趋近于总体方差除以样本量。
```
中心极限定理强调的是样本均值，而抽取的样本应服从原来分布。
也就是我的概率密度图怎么画，它的样本均值永远服从正态分布。
```

## 常见的统计检验

### T检验和Z检验
- **t 检验**：用于样本量较小或总体方差未知的情形。t 分布相比正态分布具有更厚的尾部，因此能更好地处理小样本的极端值。
- **z 检验**：用于大样本或总体方差已知的情况。

### 卡方检验
- **卡方独立性检验**：用于检测两个分类变量之间是否存在显著关联。  
- **卡方拟合优度检验**：用于检测分类变量的观测频数与期望频数之间的差异。

### F检验
- **F 检验**用于比较两个或多个组的方差是否相等，通常应用于方差分析（ANOVA）。


## 统计量和抽样分布
- [各种分布 知乎](https://www.zhihu.com/question/365697476/answer/3316448243)
- 根据统计学经验，$n>=30$ 就是大样本，$n<30$ 为小样本。


### 卡方分布
- 当多个正态随机变量的平方和服从自由度为 n 的分布时，称之为卡方分布，常用于方差的检验。

$$
X = \sum_{i=1}^{n} \frac{(o_i - e_i)^2}{e_i}
$$


这是 **卡方分布** 的统计量公式，其中：
- $o_i$ 是观察值，
- $e_i$ 是期望值，
- $n$ 是总的观测数。



根据此公式，卡方统计量 $X$ 计算的是观测值和期望值之间的差异平方与期望值的比值之和。

在一定条件下，卡方统计量 $X$ 服从自由度为$n$的 **卡方分布**，该分布用于检验分类数据的拟合优度或独立性。

----

### T分布

#### 正态分布与 t 分布的关系

- X 服从 $(0,1)$ 标准正态分布，$Y$ 服从自由度为 $n$ 的卡方分布。
- 那么： 
  $$ 
  t = \frac{X}{\sqrt{Y/n}} 
  $$ 
  服从自由度为$n$的 $t$ 分布。

- 当 t 分布自由度足够大时，$t $分布近似于标准正态分布 $N(0,1)$。

#### 单个正态总体的抽样分布
- 大样本或小样本都可以用此检验方法。
- 该方法用于判断样本均值和总体均值之间是否存在显著差异。
- 例子

    假设一个教育研究员想要评估一种新的教学方法对学生数学成绩的影响。研究员知道，根据历史数据，该学校学生的数学成绩总体均值为 70 分（总体均值 $\mu = 70$，且成绩分布接近正态分布。研究员选取了 30 名学生应用新的教学方法，并在实验结束后对这些学生进行数学成绩测试。

    对于小样本或未知总体方差的情形，可以使用 $t$ 分布来进行统计检验。公式如下：

    $$
    \frac{\bar{x} - \mu}{\frac{s}{\sqrt{n}}} \sim t(n-1)
    $$

    其中：
    - $\bar{x}$是样本均值，
    - $\mu$是总体均值，
    - $s$是样本标准差，
    - $n$是样本量，
    - 统计量服从自由度为 $(n - 1)$ 的 t 分布。

#### 两个样本均值之间显著差异的t检验公式

#### 公式1：t统计量的计算

$$
\frac{{(\bar{x} - \bar{y}) - (\mu_1 - \mu_2)}}{{S_w \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}} \sim t(n_1 + n_2 - 2)
$$

其中：
- $\bar{x}$ 和 $\bar{y}$ 分别为两组样本的均值
- $\mu_1$ 和 $\mu_2$ 是假设的总体均值（通常假设为0）
- $S_w$ 是加权样本方差
- $n_1$ 和 $n_2$ 是两组样本的数量
- $t(n_1 + n_2 - 2)$ 是具有 $(n_1 + n_2 - 2)$ 自由度的t分布

#### 公式2：加权样本方差的计算

$$
S_w^2 = \frac{{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}}{{n_1 + n_2 - 2}}
$$

其中：
- $s_1^2$ 和 $s_2^2$ 分别是两组样本的方差
- $n_1$ 和 $n_2$ 是两组样本的数量

#### 例子

假设一个营养学研究者想要比较两种不同饮食计划对体重减轻的效果。研究者随机将60名希望减肥的参与者分成两组，每组30人。第一组遵循饮食计划A，第二组遵循饮食计划B。

（注意，这里使用的是基于Welch的t检验，不假定两个总体方差相等）


#### Welch t检验（不假定两个总体方差相等）
#### 公式

$$
t = \frac{{x_1 - x_2}}{{\sqrt{\frac{{s_1^2}}{{n_1}} + \frac{{s_2^2}}{{n_2}}}}}
$$

#### 自由度的计算

Welch t检验的自由度计算比较复杂，通常使用以下公式：

$$
df = \frac{{\left( \frac{{s_1^2}}{{n_1}} + \frac{{s_2^2}}{{n_2}} \right)^2}}{{\frac{{\left( \frac{{s_1^2}}{{n_1}} \right)^2}}{{n_1 - 1}} + \frac{{\left( \frac{{s_2^2}}{{n_2}} \right)^2}}{{n_2 - 1}}}}
$$

其中：
- $x_1$和$x_2$是两个样本的均值
- $s_1^2$和$s_2^2$是两个样本的方差
- $n_1$和$n_2$是两个样本的样本量
- $df$是自由度

#### Note
- **t 分布** `相较于正态分布，具有更厚的尾部，这意味着 t 分布能够更好地处理样本量小所带来的额外变异性。`

- `T分布用于总体方差未知且样本量较小的情况。当自由度足够大时，t分布趋近于标准正态分布。`
- 为什么在未知方差或样本量较小时使用 t 分布？
    
    在统计学中，当总体方差未知或样本量较小时，通常使用 **t 分布** 而不是标准正态分布，这是由于以下两个主要原因：
    1. **尾部厚度**：
   - t 分布相比于标准正态分布具有更厚的尾部。尾部厚度意味着在 $t$ 分布中，比在正态分布中更可能观察到极端值。当样本量较小且总体方差未知时，数据中的变异性可能较大，$t$ 分布能够更好地反映这种极端值的出现概率。
   
    2. **自由度的影响**：
   - $t$ 分布的形状受到 **自由度** 的影响，而自由度与样本量直接相关。自由度越大，$t$ 分布的形状越接近正态分布。当样本量增加时，$t$ 分布的尾部厚度减小，逐渐趋近于标准正态分布。因此，随着样本量的增加，$t$ 分布与标准正态分布的差异逐渐减小。


-----

### F分布
- 当两个卡方分布的比值服从 F 分布，常用于方差分析和回归分析。
当随机变量 $Y$ 和 $Z$ 分别服从自由度为 $m$ 和 $n$ 的卡方分布时，定义变量：

$$
X = \frac{(Y / m)}{(Z / n)}
$$

- 则$X$服从第一自由度为 $m$ 和第二自由度为 $n$ 的F分布。


## A/B Test

A/B Test 是通过对比两个或多个方案，测试哪个方案表现更优的一种方法。通常通过某个指标的变化进行对比。

### A/B Test 流程

1. **明确实验目的**：
   - 新功能或多个项目的目标是否提升回报、利润、投资回报率（ROI）、转化率等。
   - 需要挑选一个关键指标，以确定新功能或哪个项目表现更优。

2. **假设检验**：
   - 提出原假设（Null Hypothesis）和备择假设（Alternative Hypothesis）。
   
3. **设定显著性水平**：
   - 设定显著性水平，并确定最小可接受阀值。

4. **确定样本量和实验时间**：
   - 计算所需样本量并设定实验持续时间。

5. **计算结果**：
   - 通过结果分析，确定是否拒绝原假设，得出哪个方案更优。

## A/B Test 可能的失败原因

1. **新奇效应**：
   - 一开始客户对新功能表现出兴趣，但随着时间推移，兴趣减弱，导致效果不再显著。

2. **样本量不足**：
   - 样本量不够大，导致实验结果不准确或无法得出显著性结论。

3. **外部因素干扰**：
   - 例如洪水、地震、政策变化等外部事件可能影响实验结果。
   - 由于对比实验有时并非同时进行，不同时间段发生的事件可能间接影响实验结果。

### A/B Test 涉及的统计学原理

- **假设检验**：通过假设检验确定实验结果的显著性，决定是否拒绝原假设。

### A/B 实验需要进行几天才能满足显著性要求？如何评估？

A/B 实验的持续时间主要取决于以下几个因素：
1. **样本量**：
   - 样本量越大，越容易观察到显著性差异。需要通过样本量计算公式估算合适的样本量（后面会具体说明）。

2. **基准转化率**：
   - 实验开始前，需要知道当前的转化率，以此为基准来判断新方案是否有显著改进。

3. **预期提升幅度**：
   - 预估新方案相较于现有方案会带来多大提升。预期提升越小，所需样本量越大。

4. **显著性水平和检验功效**：
   - 显著性水平通常设为 5%（即 95% 的置信度），检验功效通常设为 80%。显著性水平影响我们在计算样本量时的精度要求。

### 评估 A/B 实验的持续时间

评估实验持续时间的关键是：
- 确定需要的**总样本量**。
- 通过估算**日均流量**，判断需要多少天才能获得足够的样本。
  
例如：
- 如果计算出的样本量为 5000 人，且每天约有 1000 人参与实验，那么至少需要 5 天才能完成实验。

### 如何确定 A/B 实验的样本量？

样本量的计算公式通常基于以下参数：
- **基准转化率（Baseline Conversion Rate）**：实验前的转化率。
- **预期提升幅度（Minimum Detectable Effect, MDE）**：假设新方案会带来的最小转化率提升。
- **显著性水平（Significance Level, Alpha）**：通常设定为 0.05（5%）。
- **检验功效（Statistical Power, Beta）**：通常设定为 0.80（80%）。

样本量计算公式为：

$$
n = \frac{{Z_{\alpha/2}^2 \cdot p_1 (1 - p_1) + Z_{\beta}^2 \cdot p_2 (1 - p_2)}}{{(p_1 - p_2)^2}}
$$

- $p_1$是基准转化率
- $p_2$ 是预期提升后的转化率
- $Z_{\alpha/2}$是显著性水平对应的标准正态分布值（1.96 对应于 95% 的显著性水平）
- $Z_{\beta}$是检验功效对应的标准正态分布值（0.84 对应于 80% 的检验功效）

![alt text](<img-cn/ABtest-samples.jpg>)

### AB 实验流量分桶时需要保证的原则

1. **随机性**：
   - 不同的实验组的分配尽量随机，避免系统性偏差。

2. **独立性**：
   - 保证每个实验桶的用户体验是独立的，避免实验组之间的相互影响。

3. **均匀性**：
   - 各个桶内的样本量要尽量相似，以保证实验结果的可比性。

4. **一致性**：
   - 同一个用户在整个实验过程中应该始终分配到同一实验组，避免跨组跳跃带来的干扰。

### 如何解决流量不足问题

为了解决流量不足的问题，A/B 实验可以采用**多臂赌博机方法（Multi-Armed Bandit, MAB）**，其中常见的算法是**上置信界（Upper Confidence Bound, UCB）**。

- **Multi-Armed Bandit (MAB)**：
   - 这是一种在不确定环境下通过探索和利用的平衡，动态调整资源分配的策略。它在实验过程中更频繁地分配流量给表现较好的方案，从而提高流量利用率。

- **UCB 算法**：
   - 通过不断评估各个实验组的表现，并根据表现给出一个“置信界”，将更多流量分配给有潜力的实验组，同时仍然保持一定的探索以发现潜在的更优解。

### 什么是 AA 实验？

- **AA 实验**：是在没有引入任何新功能或变化的情况下，对同一组或同一个桶内的数据进行 A/B 实验，以验证是否存在显著性差异。
  
- **目的**：AA 实验的目的是确保实验的分流逻辑和数据收集方式没有问题。如果 AA 实验结果显示存在显著性差异，意味着数据采集或实验分流可能存在偏差，需要重新收集或修正数据。

- **期望结果**：AA 实验的期望结果是**没有显著性差异**，即两组数据应保持相似性。



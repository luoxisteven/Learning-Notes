# Statistics 统计学

## 两类错误

- **一类错误（假阳性）**：错误地拒绝了正确的原假设。  
  **举例**：假设一名无辜的人被控犯罪，这里零假设是“这个人是无辜的”，如果法庭错误地判定这个无辜的人有罪，那么就犯了一类错误。

- **二类错误（假阴性）**：未能拒绝错误的原假设。  
  **举例**：如果被告实际上是有罪的，但法庭判定他无罪，那么就犯了二类错误。

----
#### 一类错误和二类错误哪个更严重？

一般来说，一类错误（假阳性）通常被认为更严重。因为在统计中，原假设是我们想要去拒绝的，所以我们会把显著性水平 α 设置得较小，以减少犯一类错误的可能性。常见的 α 值为 0.05，表示我们愿意接受 5% 的概率去犯一类错误。

但在某些场景下，比如癌症筛查，`二类错误（假阴性）` 可能更严重。如果测试未能识别出实际存在的癌症（假阴性），患者可能错过最佳治疗时机。因此，需要根据具体应用场景来权衡。


## 显著性水平、统计功效和 P 值

- **显著性水平（α）**：研究者愿意接受的第一类错误（假阳性）的概率阈值。常见的 α 值为 0.05，意味着我们愿意接受 5% 的概率错误地拒绝零假设。
  
- **统计功效（1-β）**：正确拒绝零假设（检测到实际效应）的概率，表示避免犯二类错误（假阴性）的能力。统计功效越高，越有可能检测到实际存在的效应。

- **P 值**：在零假设为真的情况下，观察到当前数据结果的概率。P 值越小，表示在原假设为真的前提下，观测到这种结果的可能性越低，因此我们越倾向于拒绝零假设。

## 置信区间

- **置信区间**：用于估计总体参数的区间范围。在做区间估计时，置信区间表示根据样本数据推断的总体参数的可能范围。通常使用 95% 的置信区间，意味着我们有 95% 的信心总体参数落在此区间内。

## 不同类型的检验方法

- **t 检验**：用于比较两个样本均值是否存在显著差异，适用于总体方差未知或样本量较小的情况。

- **z 检验**：也用于比较两个样本均值，但适用于样本量较大或已知总体方差的情况。

- **卡方检验**：用于分类数据的独立性检验或拟合优度检验。独立性检验用于检查两个变量是否独立，拟合优度检验用于判断观察到的分类变量分布是否符合预期。

- **F 检验**：主要用于检验两个或多个组的方差是否显著不同，常见于方差分析（ANOVA），用于分析多个样本的均值是否存在显著差异。

## 方差分析 (ANOVA)

**ANOVA (方差分析)** 用于分析多个样本均值之间是否存在显著差异。通过比较组间变异和组内变异，来确定不同组的均值是否显著不同。ANOVA 计算的统计量 F 值的公式为：

$$
F = \frac{MSB}{MSE}
$$

其中，MSB 表示组间方差，MSE 表示组内方差。

## 单边检验和双边检验

- **单边检验**：用于假设中具有方向性预测时，测试效应是否显著。例如，研究者想验证新方案是否优于旧方案，会使用单边检验。

- **双边检验**：用于验证两个变量之间是否存在差异，而不考虑方向性。当研究者仅关心是否存在差异时，会使用双边检验。

## 辛普森悖论

**辛普森悖论**指的是在某个条件下，当分别分析两组数据时，它们可能都会满足某种性质，但当数据合并分析时，却可能导致相反的结论。  
这意味着分开讨论和合并讨论会得出相反的结论。

### 举例

假设某医院的两位医生，医生A和医生B，分别治疗了两组病人。分别计算每位医生在两组病人中的治疗成功率时，可能会得出医生A的成功率更高。然而，当合并所有病人后，结果却可能显示医生B的成功率更高。这就是辛普森悖论的体现。

### 如何避免辛普森悖论？

1. **层次化分析**：
   - 对数据进行分层，按性别、年龄段或其他重要变量进行分组分析，而不是简单地合并所有数据。分层能更清晰地揭示变量之间的关系，避免合并导致的误导性结果。

2. **细分切割**：
   - 根据数据的背景和实际情况，将数据进行细分分析。对每个子集单独处理和分析，以确保不会因合并数据而失去重要信息。

3. **样本量和样本质量**：
   - 保证每个分组中的样本量足够大，且样本质量高。样本量不足可能导致统计上的不准确性，样本的选择偏差可能导致分析结果误导。



## 假设检验
- [假设检验(知乎)](https://zhuanlan.zhihu.com/p/86178674?utm_psn=1743869140127977472)
- 标准正态分布，也称为z分布


**假设检验**是对总体参数提出一个假设值，通过样本信息判断该假设是否成立的过程。  
- **原假设（Null Hypothesis）**：通常是我们希望去拒绝的假设，例如两组均值相等。  
- **备择假设（Alternative Hypothesis）**：与原假设互补，假设两组均值不相等。

### 假设检验中的两类错误：
- **一类错误（Type I Error）**：原假设实际为真，但被错误地拒绝，即假阳性。
- **二类错误（Type II Error）**：原假设实际为假，但未能拒绝，即假阴性。

### 显著性水平和 P 值
- **显著性水平（α）**：我们愿意接受的第一类错误的概率阈值。常见的 α 值为 0.05。
- **P 值**：在原假设为真的情况下，观察到当前结果的概率。P 值越小，越倾向于拒绝原假设。

## 参数估计

**参数估计**用于通过样本来推断总体参数，分为两种方法：
1. **点估计**：使用样本统计量（如均值）直接估计总体参数。  
2. **区间估计**：在给定的置信水平下，构建一个区间来估计总体参数。例如 95% 置信区间表示 95% 的可能性下总体参数落在该区间内。
 ![alt text](<img/Pasted Graphic 17.jpg>)
 - 注意: 在未知方差时，如果大样本也可以用正态分布。$$z=（x-μ）/σ$$

### 置信区间
- [置信区间 CSDN](https://blog.csdn.net/Anne033/article/details/109739681?ops_request_misc=&request_id=&biz_id=102&utm_term=%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-109739681.142^v99^pc_search_result_base2&spm=1018.2226.3001.4187)


- **置信区间**是用样本数据估计总体参数的区间范围。  
- **置信水平**是置信区间包含总体参数的概率。常见的置信水平为 95%。
```
置信区间就是我去抽不同的样本去构建区间，有多少置信度（置信水平）的区间，能够包含真正的参数（比方说总体均值）。
置信度（置信水平）就是这些区间包含总体均值的概率。比方说，95%的置信水平表示：抽取的100个样本，有100个置信区间，其中有95个置信区间可能包含总体的真实平均值。

相当有信心落在这个置信区间内。
```

## 单边检验与双边检验

- **单边检验**：用于检测效应是否朝着假设的单一方向发展。  
- **双边检验**：用于检测两个变量是否存在差异，不考虑方向性。

## 常见的统计检验

### T检验和Z检验
- **t 检验**：用于样本量较小或总体方差未知的情形。t 分布相比正态分布具有更厚的尾部，因此能更好地处理小样本的极端值。
- **z 检验**：用于大样本或总体方差已知的情况。

### 卡方检验
- **卡方独立性检验**：用于检测两个分类变量之间是否存在显著关联。  
- **卡方拟合优度检验**：用于检测分类变量的观测频数与期望频数之间的差异。

### F检验
- **F 检验**用于比较两个或多个组的方差是否相等，通常应用于方差分析（ANOVA）。

## 大数定理与中心极限定理

### 大数定理
- **弱大数定理**：随着样本量增加，样本均值以概率收敛于总体均值。  
- **强大数定理**：随着样本量的增加，样本均值几乎必然收敛于总体均值。

### 中心极限定理
- [中心极限定理 知乎](https://zhuanlan.zhihu.com/p/259280292)
- 当`样本独立同分布 Independent and Identically Distributed`，不管是从什么分布进行抽取，`在n足够大时（样本量足够大）`，“样本的均值”趋近于总体均值，样本方差趋近于总体方差除以样本量。
```
中心极限定理强调的是样本均值，而抽取的样本应服从原来分布。
也就是我的概率密度图怎么画，它的样本均值永远服从正态分布。
```

## 统计量和抽样分布
- [各种分布 知乎](https://www.zhihu.com/question/365697476/answer/3316448243)
- 根据统计学经验，$n>=30$ 就是大样本，$n<30$ 为小样本。


### 卡方分布
- 当多个正态随机变量的平方和服从自由度为 n 的分布时，称之为卡方分布，常用于方差的检验。

$$
X = \sum_{i=1}^{n} \frac{(o_i - e_i)^2}{e_i}
$$


这是 **卡方分布** 的统计量公式，其中：
- $o_i$ 是观察值，
- $e_i$ 是期望值，
- $n$ 是总的观测数。



根据此公式，卡方统计量 $X$ 计算的是观测值和期望值之间的差异平方与期望值的比值之和。

在一定条件下，卡方统计量 $X$ 服从自由度为$n$的 **卡方分布**，该分布用于检验分类数据的拟合优度或独立性。


### T分布

#### 正态分布与 t 分布的关系

- X 服从 $(0,1)$ 标准正态分布，$Y$ 服从自由度为 $n$ 的卡方分布。
- 那么： 
  $$ 
  t = \frac{X}{\sqrt{Y/n}} 
  $$ 
  服从自由度为$n$的 $t$ 分布。

- 当 t 分布自由度足够大时，$t $分布近似于标准正态分布 $N(0,1)$。

#### 单个正态总体的抽样分布
- 大样本或小样本都可以用此检验方法。
- 该方法用于判断样本均值和总体均值之间是否存在显著差异。
- 例子

    假设一个教育研究员想要评估一种新的教学方法对学生数学成绩的影响。研究员知道，根据历史数据，该学校学生的数学成绩总体均值为 70 分（总体均值 $\mu = 70$，且成绩分布接近正态分布。研究员选取了 30 名学生应用新的教学方法，并在实验结束后对这些学生进行数学成绩测试。

    对于小样本或未知总体方差的情形，可以使用 $t$ 分布来进行统计检验。公式如下：

    $$
    \frac{\bar{x} - \mu}{\frac{s}{\sqrt{n}}} \sim t(n-1)
    $$

    其中：
    - $\bar{x}$是样本均值，
    - $\mu$是总体均值，
    - $s$是样本标准差，
    - $n$是样本量，
    - 统计量服从自由度为 $(n - 1)$ 的 t 分布。

#### 两个样本均值之间显著差异的t检验公式

#### 公式1：t统计量的计算

$$
\frac{{(\bar{x} - \bar{y}) - (\mu_1 - \mu_2)}}{{S_w \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}} \sim t(n_1 + n_2 - 2)
$$

其中：
- $\bar{x}$ 和 $\bar{y}$ 分别为两组样本的均值
- $\mu_1$ 和 $\mu_2$ 是假设的总体均值（通常假设为0）
- $S_w$ 是加权样本方差
- $n_1$ 和 $n_2$ 是两组样本的数量
- $t(n_1 + n_2 - 2)$ 是具有 $(n_1 + n_2 - 2)$ 自由度的t分布

#### 公式2：加权样本方差的计算

$$
S_w^2 = \frac{{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}}{{n_1 + n_2 - 2}}
$$

其中：
- $s_1^2$ 和 $s_2^2$ 分别是两组样本的方差
- $n_1$ 和 $n_2$ 是两组样本的数量

#### 例子

假设一个营养学研究者想要比较两种不同饮食计划对体重减轻的效果。研究者随机将60名希望减肥的参与者分成两组，每组30人。第一组遵循饮食计划A，第二组遵循饮食计划B。

（注意，这里使用的是基于Welch的t检验，不假定两个总体方差相等）


#### Welch t检验（不假定两个总体方差相等）
#### 公式

$$
t = \frac{{x_1 - x_2}}{{\sqrt{\frac{{s_1^2}}{{n_1}} + \frac{{s_2^2}}{{n_2}}}}}
$$

#### 自由度的计算

Welch t检验的自由度计算比较复杂，通常使用以下公式：

$$
df = \frac{{\left( \frac{{s_1^2}}{{n_1}} + \frac{{s_2^2}}{{n_2}} \right)^2}}{{\frac{{\left( \frac{{s_1^2}}{{n_1}} \right)^2}}{{n_1 - 1}} + \frac{{\left( \frac{{s_2^2}}{{n_2}} \right)^2}}{{n_2 - 1}}}}
$$

其中：
- $x_1$和$x_2$是两个样本的均值
- $s_1^2$和$s_2^2$是两个样本的方差
- $n_1$和$n_2$是两个样本的样本量
- $df$是自由度

#### Note
- **t 分布** `相较于正态分布，具有更厚的尾部，这意味着 t 分布能够更好地处理样本量小所带来的额外变异性。`

- `T分布用于总体方差未知且样本量较小的情况。当自由度足够大时，t分布趋近于标准正态分布。`
- 为什么在未知方差或样本量较小时使用 t 分布？
    
    在统计学中，当总体方差未知或样本量较小时，通常使用 **t 分布** 而不是标准正态分布，这是由于以下两个主要原因：
    1. **尾部厚度**：
   - t 分布相比于标准正态分布具有更厚的尾部。尾部厚度意味着在 $t$ 分布中，比在正态分布中更可能观察到极端值。当样本量较小且总体方差未知时，数据中的变异性可能较大，$t$ 分布能够更好地反映这种极端值的出现概率。
   
    2. **自由度的影响**：
   - $t$ 分布的形状受到 **自由度** 的影响，而自由度与样本量直接相关。自由度越大，$t$ 分布的形状越接近正态分布。当样本量增加时，$t$ 分布的尾部厚度减小，逐渐趋近于标准正态分布。因此，随着样本量的增加，$t$ 分布与标准正态分布的差异逐渐减小。



### F分布
- 当两个卡方分布的比值服从 F 分布，常用于方差分析和回归分析。
当随机变量 $Y$ 和 $Z$ 分别服从自由度为 $m$ 和 $n$ 的卡方分布时，定义变量：

$$
X = \frac{(Y / m)}{(Z / n)}
$$

- 则$X$服从第一自由度为 $m$ 和第二自由度为 $n$ 的F分布。


## 大数定理与中心极限定理

### 大数定理
- **弱大数定理**：随着样本量增加，样本均值以概率收敛于总体均值。  
- **强大数定理**：随着样本量的增加，样本均值几乎必然收敛于总体均值。

### 中心极限定理
- [中心极限定理 知乎](https://zhuanlan.zhihu.com/p/259280292)
- 当`样本独立同分布 Independent and Identically Distributed`，不管是从什么分布进行抽取，`在n足够大时（样本量足够大）`，“样本的均值”趋近于总体均值，样本方差趋近于总体方差除以样本量。
```
中心极限定理强调的是样本均值，而抽取的样本应服从原来分布。
也就是我的概率密度图怎么画，它的样本均值永远服从正态分布。
```